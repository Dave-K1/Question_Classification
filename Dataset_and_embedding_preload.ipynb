{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Embedding\n",
    "\n",
    "TODOs:\n",
    "- Data exploration plot\n",
    "- Add larger embedding\n",
    "- Split training data into train, val, test\n",
    "- Shuffle training data / Train in batches -> Use dataloader\n",
    "\n",
    "\n",
    "- Train on more samples\n",
    "\n",
    "\n",
    "- Schedule learning rates (optional)\n",
    "\n",
    "\n",
    "- Comments and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path_in = './data/'\n",
    "\n",
    "train = pd.read_csv(path_in + 'train.csv')\n",
    "#test = pd.read_csv(path_in + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved embedding GloVe with dimension 50\n",
    "embedding = pickle.load(open(\"./data/embeddings/GloVe50d.p\", \"rb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add some fancy plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate weight matrix\n",
    "\n",
    "Target dimension: [sequence len, sample, dimension]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of weight matrix: (45, 10000, 50)\n",
      "Ratio positives/total: 0.0637\n"
     ]
    }
   ],
   "source": [
    "seq_len = 45\n",
    "dimension = 50\n",
    "number_samples = 10000\n",
    "\n",
    "#def getWeights(seq_len, dimension, number_samples)\n",
    "## Initialize matrix\n",
    "weights = np.zeros((seq_len, number_samples, dimension))\n",
    "labels = []\n",
    "\n",
    "## Extract weight matrix for each sample\n",
    "for sample in range(number_samples):\n",
    "    sentence = train['question_text'].iloc[sample]\n",
    "    label = train['target'].iloc[sample]\n",
    "    labels.append(label)\n",
    "    \n",
    "    \n",
    "    ## Convert to lowercase and split sentence\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    ## Sepearate punctuation\n",
    "    chs = string.punctuation\n",
    "    for ch in chs:\n",
    "        idx = sentence.find(ch)\n",
    "        \n",
    "        if idx != -1:\n",
    "            sentence = sentence.replace(ch, \" \" + ch)\n",
    "            \n",
    "    sentence = sentence.split(' ')   \n",
    "    \n",
    "     ## Truncate\n",
    "    sentence = sentence[0:seq_len]\n",
    "\n",
    "    ## Find weights\n",
    "    matrix_len = len(sentence)\n",
    "    weights_matrix = np.zeros((matrix_len, dimension))\n",
    "    words_found = 0\n",
    "\n",
    "    for i, word in enumerate(sentence):\n",
    "        try: \n",
    "            weights_matrix[i] = embedding[word]\n",
    "            words_found += 1\n",
    "        except KeyError:\n",
    "            weights_matrix[i] = np.random.normal(scale=0.6, size=(dimension, ))\n",
    "\n",
    "    #print(\"{} / {} words found\".format(words_found, len(sentence)))    \n",
    "    \n",
    "    ## Pad with zeros to 45\n",
    "    z = np.zeros((1, dimension))\n",
    "    \n",
    "    for i in range(seq_len-matrix_len):      \n",
    "        weights_matrix = np.concatenate((weights_matrix, z), axis=0)\n",
    "     \n",
    "    weights[:, sample, :] = weights_matrix\n",
    "\n",
    "\n",
    "print(\"Dimension of weight matrix: {}\".format(weights.shape))    \n",
    "print(\"Ratio positives/total: {}\".format(labels.count(1)/number_samples))\n",
    "\n",
    "\n",
    "## Convert to torch tensors\n",
    "weights = torch.tensor(weights)\n",
    "weights = weights.float()  \n",
    "\n",
    "labels = torch.tensor(labels).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_layer_1):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=50, hidden_size=hidden_layer_1)       \n",
    "        self.fc1 = nn.Linear(hidden_layer_1, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        output, (h_out, _) = self.lstm(x)        \n",
    "        output = output[-1, :, :]\n",
    "        output.squeeze_()     \n",
    "        x = self.out(self.fc1(output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 20\n",
      "Loss: 0.06344214081764221 | Training accuracy: 0.934\n",
      "Epoch 2 / 20\n",
      "Loss: 0.06258990615606308 | Training accuracy: 0.934\n",
      "Epoch 3 / 20\n",
      "Loss: 0.06182772293686867 | Training accuracy: 0.934\n",
      "Epoch 4 / 20\n",
      "Loss: 0.06116997450590134 | Training accuracy: 0.934\n",
      "Epoch 5 / 20\n",
      "Loss: 0.060525763779878616 | Training accuracy: 0.934\n",
      "Epoch 6 / 20\n",
      "Loss: 0.059752628207206726 | Training accuracy: 0.934\n",
      "Epoch 7 / 20\n",
      "Loss: 0.05859176814556122 | Training accuracy: 0.934\n",
      "Epoch 8 / 20\n",
      "Loss: 0.05638273060321808 | Training accuracy: 0.934\n",
      "Epoch 9 / 20\n",
      "Loss: 0.05031564086675644 | Training accuracy: 0.934\n",
      "Epoch 10 / 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-908cf7e7b201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Backward pass / optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Function for training\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "hidden_layers = 50\n",
    "train_size = 4000\n",
    "\n",
    "\n",
    "net = Net(hidden_layers)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "## Iterate through all data\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch {} / {}\".format(epoch+1, epochs))\n",
    "    loss_sub =[]\n",
    "    acc_sub = []\n",
    "      \n",
    "    correct = 0\n",
    "    \n",
    "        \n",
    "    for sample in range(train_size):                 \n",
    "        ## Get training data\n",
    "        x = weights[:, sample, :]      \n",
    "        x.unsqueeze_(1)\n",
    "        y = labels[sample]\n",
    "        y = y.view(1)\n",
    "        \n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = net(x)\n",
    "        \n",
    "        # Evaluate output / compute loss\n",
    "        loss = criterion(output, y)       \n",
    "        \n",
    "        # Backward pass / optimize\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "                \n",
    "        ## Evaluate\n",
    "        output = np.where(output.detach().numpy() > 0.5, 1, 0)\n",
    "        correct += (output == y.numpy()).sum()\n",
    "        \n",
    "    acc = correct / train_size\n",
    "    acc_sub.append(acc)\n",
    "        \n",
    "    loss_sub.append(loss.item())\n",
    "          \n",
    "        \n",
    "    acc_list.append(np.mean(acc_sub))   \n",
    "    loss_list.append(np.mean(loss_sub)) \n",
    "    \n",
    "    #print(loss_list[-1])\n",
    "    print(\"Loss: {} | Training accuracy: {}\".format(loss_list[-1], acc_list[-1]))\n",
    "\n",
    "    \n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115321fd0>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucVWXd9/HPFyZALDWHMZWDAwoVPRnIiJqpGGqQCqZYkJZ2W4iMaXl3sOe+7w7W052dPBRqeCg8JCBqYqJYongmBhRQERvIBA+JgKSiIvp7/rjWyDQNzB6YmbVnz/f9es2Lvde69t6/7Qv5zlrXtX5LEYGZmVmnvAswM7Pi4EAwMzPAgWBmZhkHgpmZAQ4EMzPLOBDMzAxwIJiZWaagQJA0QtIySbWSzm1kf1dJ07L98yRV1tu3r6SHJD0uaYmkbg1eO1PSY9v7RczMbPs0GQiSOgOTgJHAQGCcpIENhp0GrIuIfYALgPOz15YB1wITIuIjwDDgrXrvfTzw6vZ/DTMz215lBYwZCtRGxAoASVOB0cAT9caMBr6fPZ4B/FqSgKOAxRGxCCAi1tS9QNJ7gXOA8cD0Qort0aNHVFZWFjLUzMwyCxYseCkiKpoaV0gg9ARW1nu+CjhgS2MiYpOk9UA5MAAISbOBCmBqRPw0e80PgV8AGwqoAYDKykpqamoKHW5mZoCkvxcyrpBAUCPbGjZA2tKYMuATwP6kf/jvkrQAWAPsExFfrz/f0OiHS+NJRxH06dOngHLNzGxbFDKpvAroXe95L+C5LY3J5g12BtZm2+dGxEsRsQGYBewHHAQMkfQ0cD8wQNI9jX14REyOiKqIqKqoaPKIx8zMtlEhgTAf6C+pr6QuwFhgZoMxM4FTssdjgDmR2qjOBvaV1D0LisOAJyLi0ojYMyIqSUcQT0XEsO3/OmZmtq2aPGWUzQmcSfrHvTNwVUQ8Luk8oCYiZgJXAtdIqiUdGYzNXrtO0i9JoRLArIi4rZW+i5mZbQe1p/shVFVVhSeVzcyaR9KCiKhqapyvVDYzM8CBYGZmmY4RCL/6FVx3HbzySt6VmJkVrdIPhAiYPBlOPhkqKuD442HaNHjVHTPMzOor/UCQYNEiuP9+OP10ePhhGDsWdtsNTjwRZsyADQVfLG1mVrJKPxAAOnWCgw+Giy6ClSth7lz4j/+A++5LoVBRkULi5pvh9dfzrtbMLBcdIxDq69wZDj0Ufv1rePZZmDMHvvAFuOuudDppt93gpJNg5kx48828qzUzazMdLxDq69wZDj8cLrsMnn8e/vSndKRwxx0wenQKhy9+EW67DTZuzLtaM7NW1bEDob6yMjjiCLj8cnjhBbj9djjhBLj1VjjmGPjAB9JppjvugLfeavr9zMzaGQdCY97zHhgxAq66Cv7xD/jjH2HUKLjxRhg5EnbfHb7ylXREsWlT3tWambUIB0JTunSBo4+GKVPgxRfhlltSKEydCkcdBXvsARMmpLmIt9/Ou1ozs23mQGiOrl3TkcK116ZwuOmmdJrp2mth+HDYc0+ork6rmBwOZtbOOBC21Q47wGc+A9dfn8LhhhvgsMPgt7+FYcOgd28466x0/cM77+RdrZlZkxwILaF7dxgzBqZPT+EwdSocdFCaoD7kEOjTB77+dXjooXTltJlZEXIgtLT3vhc+97k0Af3ii6mHUlUVXHIJfPzjUFkJ3/gG/OUvDgczKyq+H0JbWb8+Xew2fTrMnp2WrlZWpqWtxx6brqQuK+QW12ZmzVPo/RAcCHlYty6tVpo2LV0h/dZb8P73w6c/ncJhxAjYeee8qzSzEuFAaC9eeQXuvDMdPdx2G6xZk44UDj00rWg69ljo1y/vKs2sHXMgtEdvv526sd56awqIpUvT9oEDUzCMGgUHHJBabpiZFciBUAqWL0/hcOutcO+96aroHj3ShXLHHpsujHvf+/Ku0syKnAOh1Lz8cuqjdOutqc/SunXpKurDD0/hcOyxaXmrmVkDhQZCQctOJY2QtExSraRzG9nfVdK0bP88SZX19u0r6SFJj0taIqmbpO6SbpP0ZLb9J835ch3SLrukTqzXXZeWs95zD5x5JqxYkf7cay/42Mfgf/4nLWn1xXBm1kxNHiFI6gw8BRwJrALmA+Mi4ol6YyYC+0bEBEljgc9ExOcklQELgS9ExCJJ5cDLQFfggIi4W1IX4C7gxxFx+9Zq6dBHCFuzbNnmU0t1V0bvvns6tTRqVGqv0b173lWaWU5a8ghhKFAbESsiYiMwFRjdYMxoYEr2eAYwXJKAo4DFEbEIICLWRMTbEbEhIu7Otm0khUavQr6YNeKDH0wXu82dm44errkmrVK64YZ0X4fy8tTC+ze/STcFMjNrRCGB0BNYWe/5qmxbo2MiYhOwHigHBgAhabakhZK+1fDNJe0CHEs6SrDtVV4OJ5+crnFYvRr+/GcYPx6eeCJ1Ze3VK105/YMfwMKFvlrazN5VSCCokW0N/xXZ0pgy4BPASdmfn5E0/N0XpVNK1wMXR8SKRj9cGi+pRlLN6tWrCyjX3tWlS+rCetFFacXSY4/Bj3+ctv/gBzBkSGrCd8YZMGsWvPFG3hWbWY4KCYRVQO96z3sBz21pTPaP/M7A2mz73Ih4KSI2ALOA/eq9bjLw14i4cEsfHhGTI6IqIqoqKioKKNcaJcFHPgLf+Q48+GC6K9xvf5uua7jmmjTfUF4Oxx0HV16ZbilqZh1KIYEwH+gvqW82ATwWmNlgzEzglOzxGGBOpNnq2cC+2aqiMuAw4AkAST8iBcfXtv9rWLPtthucempqwvfSS2kp66mnptNIX/5yurfDwIHw1a/CzTenZa5mVtIKug5B0qeBC4HOwFUR8f8knQfURMRMSd2Aa4DBpCODsXWngCSdDHyHdAppVkR8S1Iv0pzDk8Cb2cf8OiKu2FodXmXUBiJg0aJ0e9C77oL77oMNG6BTJ9hvP/jkJ9NpqE98wiuXzNoJX5hmLWPjRpg3L4XDXXel1hqbNqX7Th90UAqH4cNh6NC0zcyKjgPBWserr6ZrHebMSQHxyCPpqGLHHdNS17qA2HffdFRhZrkrNBDcgN+a573vTe25R4xIz9esSdc/1B1B3J5dW1hentpq1J1i6t8/TWybWdHyEYK1rGef3Xz0cNddsGpV2t6r1+ZwGD4ceja8lMXMWotPGVn+IqC2NgXDnDnpZ82atG/AgM3hMGxYOqIws1bhQLDi8847sHjx5iOIe+9NcxISDBqUwuGTn4RDDkmnpsysRTgQrPi99RbMn7/59NJDD6VVTWVlcOCBm08xHXhgurrazLaJA8Hanw0b4IEHNp9iWrAgHVV0756ue6g7ghg82HeNM2sGB4K1fy+/nO77UHeK6Yms4/rOO8Nhh6VVTIcfDh/9qJe4mm2FA8FKz/PPbw6Iu+9ODfsgTUgPG7Y5ID78YS9xNavHgWClb+XKFAx1AfHMM2n7Bz6wORwOPxz22ccBYR2aA8E6lgj429/+NSDqOrb27JnmHuoCorIy11LN2poDwTq2CHjqqc0Bcc896YZBAH37/usRhC+SsxLnQDCrLwIef3zz0cPcuZtbeg8YsDkchg1Lp5zMSogDwWxr3n5780Vyd9+dLpJ75ZW07yMf2RwQhx3mq6it3XMgmDXHpk3p5kB1AXH//em6CAk+9rHNAXHooWnZq1k74kAw2x4bN6arqOsC4sEH4c030/UOQ4Zs7uR68MFus2FFz4Fg1pLeeCPdHKguIObNS603ysrSzYGOOAJGjUp3lfMSVysyDgSz1vTaa+mooS4g5s9PbTZ69kzBMGpUOoro2jXvSs0cCGZtavVqmDULbrkFZs9O8w91NxMaNQqOPhp23TXvKq2DciCY5eWNN9KRwy23wK23pgvkOndODfpGjYLRo2HvvfOu0joQB4JZMXjnndS19ZZbYOZMWLIkbR84cHM4DB3q5nzWqgoNhIL+FkoaIWmZpFpJ5zayv6ukadn+eZIq6+3bV9JDkh6XtERSt2z7kOx5raSLJc/EWQnq1An23x9+9KN03cOKFXDhhbD77vCzn8FBB8Gee8JXvpKOJjZsyLti68CaDARJnYFJwEhgIDBO0sAGw04D1kXEPsAFwPnZa8uAa4EJEfERYBjwVvaaS4HxQP/sZ8T2fhmzote3L5x9dmrnvXo1XHddujp6+vR0xNCjBxx3HFx1Fbz4Yt7VWgdTyBHCUKA2IlZExEZgKjC6wZjRwJTs8QxgePYb/1HA4ohYBBARayLibUl7ADtFxEORzlldDRzXAt/HrP14//vh85+HqVNTONx5J5x2WrpA7rTT0lHEwQfD+efD0qWp/YZZKyokEHoCK+s9X5Vta3RMRGwC1gPlwAAgJM2WtFDSt+qNX9XEe5p1HF26wJFHwq9+BX//OzzyCHz/+2mC+txz05zDBz8I3/hGarOxaVPeFVsJKiQQGju33/BXlS2NKQM+AZyU/fkZScMLfM/0xtJ4STWSalbXdas0K2USDBoE3/1umpB+5hm45BLo1w8uvjj1V9p9dzjlFLjxRnj11bwrthJRSCCsAnrXe94LeG5LY7J5g52Btdn2uRHxUkRsAGYB+2XbezXxngBExOSIqIqIqoqKigLKNSsxvXvDGWfAHXfASy+l+YaRI9Mk9Jgxqfnepz8Nl10GzzX6v5FZQQoJhPlAf0l9JXUBxgIzG4yZCZySPR4DzMnmBmYD+0rqngXFYcATEfE88IqkA7O5hi8Ct7TA9zErbTvtBCeeCNdckyad774bqqth2bIUGj17plVNP/xhWtXkeQdrhiYDIZsTOJP0j/tSYHpEPC7pPEmjsmFXAuWSaoFzgHOz164DfkkKlUeBhRFxW/aaM4ArgFpgOXB7i30rs46grCytUPrlL6G2Fh57DH7847T9u99NXVo/9CH4zW/g9dfzrtbaAV+YZlaKXnghnVKaPBlqamC33eCss9JRhFtodDgtemGambUzu++eLnb7y1/SaaUhQ+C//xv69IGvfS2tZDJrwIFgVsqkdFpp1qw0p3DCCTBpUuqldNJJ8OijeVdoRcSBYNZRfPSjMGVKap9x9tmpt9LgwfCpT8Gf/+wJaHMgmHU4vXvDL34BK1fC//5vOnI48sh0WmnqVF/01oE5EMw6ql12SVdBP/00XHFFaqw3bhz0758ugHvttbwrtDbmQDDr6Lp2Tb2TnngC/vCHdC3D2WenCejvftdN9joQB4KZJZ06pfsz3H8/PPAAHHpoatu9115puWptbd4VWitzIJjZv/v4x+Hmm9NRw8knp3bcAwakVhl/+Uve1VkrcSCY2ZZ96ENw+eVpnuHcc9NqpAMOSEtZb7st3RHOSoYDwcyatsceqS3GypWpVcby5XDMMbDvvmkp68aNeVdoLcCBYGaFe9/74OtfT9cyXH11mnc49dTUmvvnP4d//jPvCm07OBDMrPne8x74whdg0SK4/fZ0855vfjNd4/Dtb7sNdzvlQDCzbSfBiBHpHtHz56fHP/85VFampaxLl+ZdoTWDA8HMWkZVFUybBn/9K4wfD9dfn279OWpUWsrq1hhFz4FgZi2rXz/49a/TrT+//3148EE45JDNS1nffjvvCm0LHAhm1jp69IDvfS8Fw6RJ6Yrn44+HD3843fHNio4DwcxaV/fuMHFius3ntGnpNqBf/GK6L4OPFoqKA8HM2kZZGXz2szBvXlq6etFF6f7QGzbkXZllHAhm1rY6d04Xt110UWqm98lPwurVeVdlOBDMLC9nnQU33piuZTjoIHjqqbwr6vAcCGaWn898Jt3zef36tArpwQfzrqhDcyCYWb4OPBAefhh23TWdPrrxxrwr6rAKCgRJIyQtk1Qr6dxG9neVNC3bP09SZba9UtLrkh7Nfi6r95pxkpZIWizpDkk9WupLmVk7s/fe6ehgyJA00XzBBb6QLQdNBoKkzsAkYCQwEBgnaWCDYacB6yJiH+AC4Px6+5ZHxKDsZ0L2nmXARcDhEbEvsBg4c7u/jZm1Xz16pPbaxx8P55yT7trmZaltqpAjhKFAbUSsiIiNwFRgdIMxo4Ep2eMZwHBJ2sp7KvvZMRu3E+BuWGYd3Q47wPTp8J//Cb/6FZxwgpeltqFCAqEnsLLe81XZtkbHRMQmYD1Qnu3rK+kRSXMlHZKNeQs4A1hCCoKBwJWNfbik8ZJqJNWs9tI0s9LXqVNqkHfxxTBzJhx+uO/r3EYKCYTGftNveHJvS2OeB/pExGDgHOD3knaS9B5SIAwG9iSdMvpOYx8eEZMjoioiqioqKgoo18xKwle/CjfdBEuWeFlqGykkEFYBves978W/n955d0w2P7AzsDYi3oyINQARsQBYDgwABmXblkdEANOBj2/H9zCzUnTccWlZ6iuvpFB44IG8KypphQTCfKC/pL6SugBjgZkNxswETskejwHmRERIqsgmpZHUD+gPrACeBQZKqvuV/0jAjdPN7N8dcAA89BCUl8Pw4XDDDXlXVLKaDIRsTuBMYDbpH+3pEfG4pPMkjcqGXQmUS6olnRqqW5p6KLBY0iLSZPOEiFgbEc8BPwDulbSYdMTw45b8YmZWQvbeO4VCVVXqh/SLX3hZaitQtKP/qFVVVVFTU5N3GWaWlzfeSJ1Sb7gBzjwTLrww9UayrZK0ICKqmhpX1hbFmJm1iG7dYOpU2GuvtBLpmWfSndm6d8+7spLg1hVm1r506gQ/+1m6TuGPf/Sy1BbkQDCz9unMM9MtOZcsSf2Qli3Lu6J2z4FgZu3XqFFwzz3w2mupW+r99+ddUbvmQDCz9m3o0LQCqUcPOOKI1PrCtokDwczav379UrfU/feHz30uTTi3oxWUxcKBYGalobwc/vSndJ3CN7+ZWl+4W2qzeNmpmZWObt3SMtS99korkeqWpe64Y96VtQs+QjCz0tKpE/z0pzBpEtx2GwwbBv/4R95VtQsOBDMrTRMnwh/+AE88kZalPvlk3hUVPQeCmZWuY49Ny1I3bEjLUu+7L++KipoDwcxK2/77w8MPw267pWWp06blXVHRciCYWenr2zctSz3gABg7Ns0xeFnqv3EgmFnHsOuucOedKRC+/W2oroZNm/Kuqqh42amZdRzdusF116VlqeefDytXpu6pXpYK+AjBzDqaTp3gJz+BSy6BWbPgsMPghRfyrqooOBDMrGM64wy45RZYujTdr3mp7+LrQDCzjuuYY2DuXHj99bQsde7cvCvKlQPBzDq2qqq0LHX33eHoo2Ht2rwryo0DwcyssjL1PHrtNfjd7/KuJjcOBDMzgEGD0mmjSy+Fd97Ju5pcFBQIkkZIWiapVtK5jezvKmlatn+epMpse6Wk1yU9mv1cVu81XSRNlvSUpCclndBSX8rMbJtUV0NtbWqj3QE1GQiSOgOTgJHAQGCcpIENhp0GrIuIfYALgPPr7VseEYOynwn1tv8X8GJEDMjet2PP5phZ/k44ASoqUqfUDqiQI4ShQG1ErIiIjcBUYHSDMaOBKdnjGcBwSWriff8D+F+AiHgnIl4qvGwzs1bQtSt85Svwxz/C00/nXU2bKyQQegIr6z1flW1rdExEbALWA+XZvr6SHpE0V9IhAJJ2yfb9UNJCSTdI+kBjHy5pvKQaSTWrV68u7FuZmW2r008HCX7zm7wraXOFBEJjv+k37Aq1pTHPA30iYjBwDvB7STuRWmb0Ah6IiP2Ah4CfN/bhETE5IqoioqqioqKAcs3MtkOfPqlt9hVXwJtv5l1NmyokEFYBves97wU8t6UxksqAnYG1EfFmRKwBiIgFwHJgALAG2ADcnL3+BmC/bfwOZmYtq7oaXnoJbrgh70raVCGBMB/oL6mvpC7AWGBmgzEzgVOyx2OAORERkiqySWkk9QP6AysiIoBbgWHZa4YDT2zXNzEzaynDh0P//h1ucrnJQMjmBM4EZgNLgekR8bik8ySNyoZdCZRLqiWdGqpbmnoosFjSItJk84SIqLsM8NvA9yUtBr4A/GdLfSkzs+3SqVO6BefDD8PChXlX02YU7egmEVVVVVFTU5N3GWbWEbz8Muy5J3z+82k+oR2TtCAiqpoa5yuVzcwas8sucNJJ8Pvfw7p1eVfTJhwIZmZbUl2dOqF2kP5GDgQzsy0ZNCjdK+GSSzpEfyMHgpnZ1tT1N/rzn/OupNU5EMzMtmbMmA7T38iBYGa2NV27wpe/nPob/f3veVfTqhwIZmZNOf309GeJ9zdyIJiZNWWvvdL9l0u8v5EDwcysENXVsHo1zJiRdyWtxoFgZlaII44o+f5GDgQzs0J06gRnnAEPPQSPPJJ3Na3CgWBmVqhTT4UddkgXqpUgB4KZWaHe//7U7O6661LzuxLjQDAza44S7m/kQDAza47Bg0u2v5EDwcysuSZOhL/+Fe66K+9KWpQDwcysuU48EXr0KLklqA4EM7PmqutvdOut8MwzeVfTYhwIZmbbYsKE9GcJ9TdyIJiZbYu6/kaXX14y/Y0cCGZm22rixNTf6MYb866kRRQUCJJGSFomqVbSuY3s7yppWrZ/nqTKbHulpNclPZr9XNbIa2dKemx7v4iZWZs78kjYZ5+SmVxuMhAkdQYmASOBgcA4SQMbDDsNWBcR+wAXAOfX27c8IgZlPxMavPfxwKvb8wXMzHLTqVM6SnjwQXj00byr2W6FHCEMBWojYkVEbASmAqMbjBkNTMkezwCGS9LW3lTSe4FzgB81r2QzsyJSQv2NCgmEnsDKes9XZdsaHRMRm4D1QHm2r6+kRyTNlXRIvdf8EPgFsGFrHy5pvKQaSTWrV68uoFwzszZUQv2NCgmExn7TjwLHPA/0iYjBpKOB30vaSdIgYJ+IuLmpD4+IyRFRFRFVFRUVBZRrZtbGJk6EDRtgypSmxxaxQgJhFdC73vNewHNbGiOpDNgZWBsRb0bEGoCIWAAsBwYABwFDJD0N3A8MkHTPtn8NM7Mc7bcfHHhgu+9vVEggzAf6S+orqQswFpjZYMxM4JTs8RhgTkSEpIpsUhpJ/YD+wIqIuDQi9oyISuATwFMRMWz7v46ZWU6qq+Gpp2DOnLwr2WZNBkI2J3AmMBtYCkyPiMclnSdpVDbsSqBcUi3p1FDd0tRDgcWSFpEmmydExNqW/hJmZrkbM6bd9zdSRMPpgOJVVVUVNTU1eZdhZta473wHfvpT+NvfoE+fvKt5l6QFEVHV1DhfqWxm1lJOPx0iYPLkvCvZJg4EM7OWUlnZrvsbORDMzFpSdTW8+CLcdFPelTSbA8HMrCW14/5GDgQzs5bUqROccQY88AAsWpR3Nc3iQDAza2mnngrdurW7/kYOBDOzlrbrrqm/0bXXtqv+Rg4EM7PWUF2d+htdfXXelRTMgWBm1hr22w8OOCCdNmonFwA7EMzMWkt1NSxbBnfdlXclBXEgmJm1lhNPTP2N2snksgPBzKy1dOsGp50Gt9wCK1c2PT5nDgQzs9Y0YUK76W/kQDAza02VlXD00am/0caNeVezVQ4EM7PWVl0N//gH3Hhj3pVslQPBzKy1HXUU7L130U8uOxDMzFpbXX+j+++HxYvzrmaLHAhmZm3hS18q+v5GDgQzs7aw664wblzqb7R+fd7VNMqBYGbWVqqr4bXXYMqUvCtplAPBzKytDBlS1P2NCgoESSMkLZNUK+ncRvZ3lTQt2z9PUmW2vVLS65IezX4uy7Z3l3SbpCclPS7pJy35pczMitbEiam/0Zw5eVfyb5oMBEmdgUnASGAgME7SwAbDTgPWRcQ+wAXA+fX2LY+IQdnPhHrbfx4RHwIGAwdLGrk9X8TMrF347GehvLwoJ5cLOUIYCtRGxIqI2AhMBUY3GDMaqDspNgMYLklbesOI2BARd2ePNwILgV7NLd7MrN2p399o1aq8q/kXhQRCT6B+V6ZV2bZGx0TEJmA9UJ7t6yvpEUlzJR3S8M0l7QIcC7SP/rBmZttrwgR4552i629USCA09pt+w9mQLY15HugTEYOBc4DfS9rp3RdJZcD1wMURsaLRD5fGS6qRVLN69eoCyjUzK3J9+6b+RpMnF1V/o0ICYRXQu97zXsBzWxqT/SO/M7A2It6MiDUAEbEAWA4MqPe6ycBfI+LCLX14REyOiKqIqKqoqCigXDOzdmDixNTf6Kab8q7kXYUEwnygv6S+kroAY4GZDcbMBE7JHo8B5kRESKrIJqWR1A/oD6zInv+IFBxf2/6vYWbWznzqU9CvX1FNLjcZCNmcwJnAbGApMD0iHpd0nqRR2bArgXJJtaRTQ3VLUw8FFktaRJpsnhARayX1Av6LtGppYbYk9cst+s3MzIpZXX+j++6DJUvyrgYARRFeHLElVVVVUVNTk3cZZmYtY+1a6NkTTj0VLr201T5G0oKIqGpqnK9UNjPLS11/o2uuKYr+Rg4EM7M8TZyY+htdfXXelTgQzMxyVVUFQ4cWRX8jB4KZWd4mToQnn4S77861DAeCmVnePve5ouhv5EAwM8tbXX+jP/wh1/5GDgQzs2JQBP2NHAhmZsWgb1/49Kfh8stz62/kQDAzKxYTJ8ILL8DNN+fy8Q4EM7NiMWJErv2NHAhmZsWirr/Rvffm0t/IgWBmVky+9KW06iiHowQHgplZMSkvh7FjU3+jf/6zTT/agWBmVmxy6m/kQDAzKzb7759+2ri/kQPBzKwYVVfD0qVwzz1t9pEOBDOzYvTZz6b7JUya1GYf6UAwMytGO+ywub/Rs8+2yUc6EMzMilUb9zdyIJiZFat+/WDkyBQIb73V6h/nQDAzK2ZnnQXDh7fJPZcLCgRJIyQtk1Qr6dxG9neVNC3bP09SZba9UtLrkh7Nfi6r95ohkpZkr7lYklrqS5mZlYxPfQquvRZ69Gj1j2oyECR1BiYBI4GBwDhJAxsMOw1YFxH7ABcA59fbtzwiBmU/E+ptvxQYD/TPfkZs+9cwM7PtVcgRwlCgNiJWRMRGYCowusGY0cCU7PEMYPjWfuOXtAewU0Q8FBEBXA0c1+zqzcysxRQSCD2BlfWer8q2NTomIjYB64HybF9fSY9ImivpkHrj698nrrH3NDOzNlRWwJjGftNveC31lsY8D/SJiDWShgB/kPSRAt8zvbE0nnRqiT59+hRQrpmZbYsMhnrEAAAEtUlEQVRCjhBWAb3rPe8FPLelMZLKgJ2BtRHxZkSsAYiIBcByYEA2vlcT70n2uskRURURVRUVFQWUa2Zm26KQQJgP9JfUV1IXYCwws8GYmcAp2eMxwJyICEkV2aQ0kvqRJo9XRMTzwCuSDszmGr4I3NIC38fMzLZRk6eMImKTpDOB2UBn4KqIeFzSeUBNRMwErgSukVQLrCWFBsChwHmSNgFvAxMiYm227wzgd8AOwO3Zj5mZ5UTRhq1Vt1dVVVXU1NTkXYaZWbsiaUFEVDU5rj0FgqTVwN+38eU9gJdasJyW4rqax3U1j+tqnlKta6+IaHIStl0FwvaQVFNIQrY119U8rqt5XFfzdPS63MvIzMwAB4KZmWU6UiC0TUPx5nNdzeO6msd1NU+HrqvDzCGYmdnWdaQjBDMz24qSD4Sm7uWQF0lXSXpR0mN511KfpN6S7pa0VNLjks7OuyYASd0k/UXSoqyuH+RdUx1JnbMGjn/Mu5b6JD2d3XPkUUlFcwGPpF0kzZD0ZPb37KAiqOmD9e7b8qikf0r6Wt51AUj6evZ3/jFJ10vq1mqfVcqnjLK2GU8BR5L6J80HxkXEE7kWBkg6FHgVuDoi/k/e9dTJWpPvERELJb0PWAAcl/d/s6zFyY4R8aqk9wD3A2dHxMN51gUg6RygitTS/Zi866kj6WmgKiKKal29pCnAfRFxRdYOp3tEvJx3XXWyfzeeBQ6IiG297qmlaulJ+rs+MCJelzQdmBURv2uNzyv1I4RC7uWQi4i4l9Tmo6hExPMRsTB7/AqwlCJoTR7Jq9nT92Q/uf82I6kXcDRwRd61tAeSdiK1tLkSICI2FlMYZIaTbuyVaxjUUwbskDUO7c4WGoG2hFIPhELu5WBbkN0KdTAwL99KkuzUzKPAi8CfIqIY6roQ+BbwTt6FNCKAOyUtyNrIF4N+wGrgt9lptisk7Zh3UQ2MBa7PuwiAiHgW+DnwDOl2Ausj4s7W+rxSD4SC77tg/0rSe4Ebga9FxD/zrgcgIt6OiEGkdulDJeV6qk3SMcCLWWv3YnRwROxHuv1tdXaaMm9lwH7ApRExGHgNKKa5vS7AKOCGvGsBkPR+0lmNvsCewI6STm6tzyv1QCjkXg7WQHaO/kbguoi4Ke96GspOMdxD/vfhPhgYlZ2rnwp8UtK1+Za0WUQ8l/35InAz6RRq3lYBq+od3c0gBUSxGAksjIh/5F1I5gjgbxGxOiLeAm4CPt5aH1bqgVDIvRysnmzy9kpgaUT8Mu966mT31tgle7wD6X+UJ/OsKSK+ExG9IqKS9HdrTkS02m9vzSFpx2xRANkpmaOA3Fe0RcQLwEpJH8w2DQdyX+RRzziK5HRR5hngQEnds/83h5Pm9VpFIbfQbLe2dC+HnMsCQNL1wDCgh6RVwPci4sp8qwLSb71fAJZk5+sB/m9EzMqxJoA9gCnZCpBOwPSIKKplnkXmA8DN6d8QyoDfR8Qd+Zb0rq8C12W/pK0AvpRzPQBI6k5akXh63rXUiYh5kmYAC4FNwCO04lXLJb3s1MzMClfqp4zMzKxADgQzMwMcCGZmlnEgmJkZ4EAwM7OMA8HMzAAHgpmZZRwIZmYGwP8HzHcVsbbaOmkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
